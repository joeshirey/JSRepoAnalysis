# Instruction
You are an expert evaluator. Your task is to evaluate the quality of the responses generated by AI models.
We will provide you with the user input and AI-generated responses.
You should first read the user input carefully for analyzing the task, and then evaluate the quality of the responses based on the Criteria provided in the Evaluation section below.
You will answer each of the yes/no questions in the Criteria. Provide your response to each question where the answer is no (do not enumerate the ones that are YES in the response, only the NOs). Explain your reasoning for each answer to the Criteria. Provide lines of code that support your reasoning. Provide an overall score as a percentage, between 0.0 and 1.0, rounded to two decimal places of the number of YES answers compared to the total number of questions.


# Evaluation
## Metric Definition
You will be assessing the model's the ability to follow the Google Cloud code sample style guide, provided under Criteria. 

# Criteria

All samples should make best-efforts to achieve the following goals wherever
possible.

**I. Core Goals & Usability**



1. **Copy-Paste-Runnable:** Can a user likely copy, paste, and run this code in a typical environment for its language with minimal (or clearly documented) setup? (YES/NO)
2. **Teaches Through Code:** Does the sample clearly demonstrate _how_ to use a service/feature and implicitly or explicitly teach _why_ certain best practices are used? (YES/NO)
3. **Idiomatic for its Language:** Does the code appear to follow common, idiomatic patterns and best practices generally accepted by the community for _this specific programming language_? (YES/NO)

**II. Structure & Metadata**



1. **Region Tags Present:** Does the code snippet include start and end region tags to define the displayed portion? (YES/NO)
2. **Region Tag Uniqueness:** Are the region tags structured to be globally unique (e.g., following a prefix + descriptive name pattern)? (YES/NO)
    *   _(Assumes the LLM can't truly verify global uniqueness but can check for a pattern that promotes it)._
3. 
4. **Region Tag Consistency:** If this snippet is conceptually the same as snippets in other languages, do the region tags appear consistent (same descriptive part)? (YES/NO)
    *   _(This may be hard for an LLM to verify without cross-language context, but it can check if the tag _
5. 
6. **Region Tag Product Prefix:** Does the region tag begin with an apparent product-specific prefix? (YES/NO)
7. **Region Tag Casing:** Do region tags use `snake_case`? (YES/NO)
8. **One Sample Per File:** Does the file appear to contain only one primary, distinct code sample or operation? (YES/NO)
9. **Sample Description:** Is there a top-level comment block that describes:
    *   a. What the snippet does? (YES/NO)
    *   b. Any required setup or prerequisites (e.g., resources, environment variables)? (YES/NO)
    *   c. Any required user-provided input values? (YES/NO)
10. 
11. **Dependencies Declared:** Are all necessary import statements or dependency declarations for the code to run included? (YES/NO)

**III. Implementation & Best Practices**



1. **Single Main Function/Flow:** Is the core logic of the sample encapsulated within a single main function or a clear, primary execution flow? (YES/NO)
2. **Descriptive Main Function Name:** If a main function is used, does its name accurately describe the operation it performs? (YES/NO)
3. **Language-Appropriate Naming Conventions:** Do identifiers (variables, function names) generally follow common naming conventions for the specific language (e.g., `camelCase`, `snake_case` as appropriate for the language's norms, _not_ necessarily the region tag style)? (YES/NO)
4. **Minimal Arguments for Main Flow:** Does the main function/flow only accept arguments that are essential for the sample's operation or testing (and not for values that could be hard-coded)? (YES/NO)
5. **No Return from Main Sample Execution:** Does the primary execution path of the sample avoid returning a value, instead focusing on side effects (like printing)? (YES/NO)
    *   _(Note: Helper functions _
6. 
7. **Prints Results:** Does the sample demonstrate interaction with results by printing relevant information to standard output? (YES/NO)
8. **Arrange-Act-Assert (or Demonstrate) Pattern:** Does the sample generally follow a structure of:
    *   a. Arranging/setting up components? (YES/NO)
    *   b. Acting/performing the main operation? (YES/NO)
    *   c. Asserting/demonstrating the result (typically via printing)? (YES/NO)
9. 
10. **Client Initialization Shown:** Is the initialization of any necessary API clients clearly shown? (YES/NO)
11. **Client Cleanup Shown (if applicable):** If the client or resources used require explicit cleanup (e.g., closing a connection, releasing a resource), is this demonstrated? (YES/NO)
12. **Client Lifecycle Commented (if complex):** Is there a comment clarifying client lifecycle best practices (e.g., reuse, thread-safety) if relevant and not obvious? (YES/NO)
13. **Error Handling Present:** Does the sample include error handling for common issues that might arise from service interactions (e.g., using `try-catch` or equivalent)? (YES/NO)
14. **Helpful Error Messages:** If errors are caught, is a helpful message printed or logged? (YES/NO)
15. **Language Version Compatibility:** Does the code use features generally compatible with broadly supported versions of the language (avoiding overly bleeding-edge or deprecated features)? (YES/NO)
16. **Useful Comments (Contextual):** Do comments primarily add context not obvious from the code, rather than just restating what the code does? (YES/NO)
17. **Grammatically Correct Comments:** Are comments readable and grammatically correct? (YES/NO)
18. **Focused on Single Operation:** Is the sample primarily focused on demonstrating one specific operation or feature, with a clear primary execution path (even with error handling)? (YES/NO)
19. **Minimal Unnecessary Complexity:** Does the sample avoid unnecessary conditional logic or loops that are not core to demonstrating the feature? (YES/NO)
20. **Placeholder for User Values:** Are any values that the user _must_ customize (e.g., Project ID, bucket name) clearly denoted, typically using `ALL_UPPER_SNAKE_CASE`? (YES/NO)


# User Inputs and AI-generated Response

## User Inputs

\n\n{code}
